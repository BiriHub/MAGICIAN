{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690fec77",
   "metadata": {},
   "source": [
    "## Setting up the environment for the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0471610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie necessarie\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.robotparser\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987235d5",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.walletexplorer.com\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e258d",
   "metadata": {},
   "source": [
    "### Check the robot.txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Function to check if a URL is allowed by robots.txt\n",
    "# def is_allowed(url):\n",
    "#     return rp.can_fetch('*', url)\n",
    "# # Function to scrape a URL if allowed by robots.txt\n",
    "# def scrape_url(url):\n",
    "#     if is_allowed(url):\n",
    "#         response = requests.get(url)\n",
    "#         # Process the response\n",
    "#         print(response.status_code)\n",
    "#         print(response.text)\n",
    "#     else:\n",
    "#         print(f\"Scraping blocked by robots.txt: {url}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Parse the robots.txt file \n",
    "# rp = urllib.robotparser.RobotFileParser()\n",
    "# rp.set_url(BASE_URL + '/robots.txt')\n",
    "# rp.read()\n",
    "\n",
    "# if not rp.mtime():\n",
    "#    print(\"robots.txt could not be read or is not present.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a943e",
   "metadata": {},
   "source": [
    "## Extracting DeepBit.net and DiceOnCrack.com wallet addresses\n",
    "\n",
    "I create a small pipeline to scrape the walletexplorer website and then extract the wallet addresses from the pages of the two websites by using two functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_walletexplorer_page():\n",
    "    ''' Scrape the main page of WalletExplorer to find the search form '''\n",
    "    try:\n",
    "        time.sleep(5)  # Pause for 5 seconds to avoid overwhelming the server\n",
    "        print(\"Accessing WalletExplorer main page...\")\n",
    "        main_walletexplore_page = requests.get(BASE_URL, headers=HEADERS)\n",
    "        main_walletexplore_page.raise_for_status()\n",
    "        print(\"WalletExplorer has been successfully accessed\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error while accessing WalletExplorer:\", e)\n",
    "        return None\n",
    "    print(main_walletexplore_page.status_code)\n",
    "    return main_walletexplore_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce59b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_wallet_address(html_page,service_name):\n",
    "    \n",
    "    # Search the form in the page\n",
    "    soup = BeautifulSoup(html_page.text, 'html.parser')\n",
    "    search_form = soup.find('form', {'class':'main'})\n",
    "\n",
    "    action_form = search_form.get('action')\n",
    "\n",
    "    target_url = BASE_URL + action_form if action_form.startswith('/') else action_form\n",
    "\n",
    "\n",
    "    # Open search page regarding 'service_name' and open the wallet addresses page\n",
    "    try: \n",
    "        time.sleep(5)  # Pause for 5 seconds to avoid overwhelming the server\n",
    "        print(f\"Accessing the search page for '{service_name}'...\")\n",
    "\n",
    "        search_page = requests.get(target_url, headers=HEADERS, params={'wallet' :service_name})\n",
    "        search_page.raise_for_status()\n",
    "        print(f'Search page for \"{service_name}\" has been successfully accessed')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error while accessing the search page:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "    ## Scrape the search results and extract the wallet addresses of 'service_name'\n",
    "    soup = BeautifulSoup(search_page.text, 'html.parser')\n",
    "\n",
    "    # Find the url of the wallet addresses page\n",
    "    span = soup.find('span', {'class': 'showother'})\n",
    "\n",
    "    wallet_link = span.find('a').get('href')\n",
    "    wallets_url = BASE_URL + wallet_link # create the full URL for the wallet addresses page\n",
    "    try:\n",
    "        time.sleep(5)  # Pause for 5 seconds to avoid overwhelming the server        \n",
    "        wallet_addr_page = requests.get(wallets_url, headers=HEADERS)\n",
    "        wallet_addr_page.raise_for_status()\n",
    "        print(f\"Wallet addresses page for '{service_name}' has been successfully accessed\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error while accessing the wallets page: {e}\")\n",
    "        return None     \n",
    "\n",
    "    # Scrape the wallet addresses page extracting the information from the table\n",
    "    soup = BeautifulSoup(wallet_addr_page.text, 'html.parser')\n",
    "\n",
    "    # Save the wallet address of 'service_name'\n",
    "    tmp = []\n",
    "\n",
    "    # Find the table containing the wallet addresses\n",
    "    wallet_table = soup.find('table')\n",
    "\n",
    "    for row in wallet_table.find_all('tr'):\n",
    "        col = row.find('td')\n",
    "        if col and col.find('a', href=True):\n",
    "            addr = col.find('a')\n",
    "            tmp.append(addr.text.strip())\n",
    "    \n",
    "    return pd.Series(tmp, name='hash') if tmp else pd.Series([], name='hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abacc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepbit_service = \"DeepBit.net\"\n",
    "# diceoncrack_service = \"DiceOnCrack.com\"\n",
    "\n",
    "# # Open the main page of WalletExplorer\n",
    "\n",
    "# main_walletexplore_page = get_walletexplorer_page()\n",
    "# if main_walletexplore_page is None:\n",
    "#     print(\"Failed to retrieve the main WalletExplorer page.\")\n",
    "# else:\n",
    "#     # Get the wallet addresses for DeepBit.net\n",
    "#     print(f\"Searching for wallet addresses of {deepbit_service}...\")\n",
    "#     deepbit_wallet_addresses = scraping_wallet_address(main_walletexplore_page, deepbit_service)\n",
    "#     if deepbit_wallet_addresses is None:\n",
    "#         print(f\"Failed to retrieve wallet addresses for {deepbit_service}.\")\n",
    "    \n",
    "#     # Get the wallet addresses for DiceOnCrack.com\n",
    "#     print(f\"Searching for wallet addresses of {diceoncrack_service}...\")\n",
    "#     diceoncrack_wallet_addresses = scraping_wallet_address(main_walletexplore_page, diceoncrack_service)\n",
    "#     if diceoncrack_wallet_addresses is None:\n",
    "#         print(f\"Failed to retrieve wallet addresses for {diceoncrack_service}.\")\n",
    "# #Print the results\n",
    "# print(f\"DeepBit.net wallet addresses: {deepbit_wallet_addresses}\")\n",
    "# print(f\"DiceOnCrack.com wallet addresses: {diceoncrack_wallet_addresses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "transactions = pd.read_csv('transactions.csv', engine='pyarrow')\n",
    "transactions.columns = ['timestamp', 'blockId', 'txId', 'isCoinbase', 'fee']\n",
    "\n",
    "outputs = pd.read_csv('outputs.csv', engine='pyarrow')\n",
    "outputs.columns = ['txId', 'position', 'addressId', 'amount', 'scripttype']\n",
    "\n",
    "inputs = pd.read_csv('inputs.csv', engine='pyarrow')\n",
    "inputs.columns = ['txId', 'prevTxId', 'prevTxpos']\n",
    "\n",
    "mapping = pd.read_csv('mapping.csv', engine='pyarrow', header=None)\n",
    "mapping.columns = ['hash', 'addressId']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe0786",
   "metadata": {},
   "source": [
    "## Deepbit.net's mining pool analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db954734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to map address hash -> addressId\n",
    "def map_wallet_addresses(wallet_addresses,mapping_dt):\n",
    "    \"\"\"\n",
    "    Mappa una lista di wallet addresses ai rispettivi addressId nel dataset di mapping.\n",
    "    Restituisce un set di addressId trovati e stampa eventuali indirizzi non trovati.\n",
    "    \"\"\"\n",
    "    mapped_addresses = mapping_dt.merge(wallet_addresses,on ='hash')['addressId']\n",
    "    if mapped_addresses.empty:\n",
    "        print(\"No addresses were mapped.\")\n",
    "        return pd.Series([], name='addressId')\n",
    "    \n",
    "    print(f\"Mapped addresses : {mapped_addresses}\")\n",
    "    return mapped_addresses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Identify the mapping between wallet addresses on the dataset\n",
    "if mapping is None:\n",
    "    print(\"Failed to retrieve the mapping dataset.\")\n",
    "    exit(1)\n",
    "\n",
    "deepbit_wallet_addresses = pd.Series([\"1VayNert3x1KzbpzMGt2qdqrAThiRovi8\",\"13NGmRF2SVRg3aKdGNVhXLmhA1JT9p87a8\"],name='hash')\n",
    "\n",
    "deepbit_mapped_addresses = map_wallet_addresses(deepbit_wallet_addresses,mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd00271",
   "metadata": {},
   "source": [
    "## 1) Deepbit.net's mined block distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9212c",
   "metadata": {},
   "source": [
    "Extract the transactions of DeepBit.net which are the transactions that have at least one input or output address of DeepBit.net.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wallet_transactions(wallet_mapped_addresses, transactions, inputs, outputs):\n",
    "    \"\"\"Finds all transactions related to the specified service addresses.\"\"\"\n",
    "\n",
    "    # Find all outputs information (address, amount, ...)\n",
    "    diceoncrack_output_transactions = outputs.merge(wallet_mapped_addresses,on='addressId') \n",
    "    \n",
    "    # Find all inputs information (address, amount, ...)\n",
    "    renamed_outputs= diceoncrack_output_transactions.rename(columns={'txId': 'prevTxId', 'position': 'prevTxpos'})\n",
    "\n",
    "    wallet_input_transactions = inputs.merge(renamed_outputs,on=['prevTxId', 'prevTxpos'])\n",
    "\n",
    "    # Find all transactions that have at least one output address of DiceOnCrack.com\n",
    "    df_union = pd.concat([diceoncrack_output_transactions['txId'], wallet_input_transactions['txId']], axis=0,ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    wallet_transactions = transactions.merge(df_union,on='txId') \n",
    "\n",
    "    return wallet_transactions\n",
    "\n",
    "\n",
    "# Find the transactions related to Deepbit.net\n",
    "deepbit_transactions = find_wallet_transactions(deepbit_mapped_addresses, transactions, inputs, outputs)\n",
    "print(f\"Number of transactions related to Deepbit.net: {len(deepbit_transactions)}\")\n",
    "\n",
    "# # DEBUG\n",
    "# print(deepbit_transactions.head(20))\n",
    "# print(deepbit_transactions.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f884570",
   "metadata": {},
   "source": [
    "Find the distribution of the mined blocks by DeepBit.net in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403145c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Find the transaction patterns for the wallet addresses\n",
    "# 1 transaction - coinbase transaction\n",
    "\n",
    "coinbase_transactions = transactions[transactions['isCoinbase'] == 1]['txId']\n",
    "merged_outputs_first_transact= outputs.merge(coinbase_transactions, on='txId')\n",
    "# print(merged_outputs_first_transact.tail(20))\n",
    "\n",
    "# 2 Transaction - Deepbit transactions\n",
    "deepbit_asoutput_transactions = outputs.merge(deepbit_mapped_addresses, on='addressId')\n",
    "tmp = deepbit_asoutput_transactions.merge(deepbit_transactions, on='txId')\n",
    "inputs_second_transaction = tmp.merge(inputs, on='txId')\n",
    "# MERGE\n",
    "merged_outputs_first_transact.rename(columns={'txId': 'prevTxId', 'position': 'prevTxpos'}, inplace=True)\n",
    "deepbit_mined_block_transact = inputs_second_transaction.merge(merged_outputs_first_transact, on=['prevTxId', 'prevTxpos']).drop_duplicates()[['txId', 'prevTxId', 'prevTxpos','timestamp']]\n",
    "\n",
    "# DEBUG\n",
    "print(f\"Number of transactions in the base pattern: {len(deepbit_mined_block_transact)}\")\n",
    "# print(base_pattern.head(20))\n",
    "\n",
    "# # Conta gli input per transazione\n",
    "# inputs_count = (base_pattern.groupby('txId')['prevTxId'].count()).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Lets prepare the data for Deepbit.net block distribution\n",
    "deepbit_block_distribution = deepbit_mined_block_transact.copy()\n",
    "deepbit_block_distribution['timestamp'] = pd.to_datetime(deepbit_block_distribution['timestamp'], unit='s')\n",
    "deepbit_block_distribution.set_index('timestamp', inplace=True)\n",
    "\n",
    "# 1. Conteggio giornaliero\n",
    "daily = deepbit_block_distribution.resample('D').size()\n",
    "\n",
    "# 2. Conteggio settimanale\n",
    "weekly = deepbit_block_distribution.resample('W').size()\n",
    "\n",
    "# 3. Conteggio mensile\n",
    "monthly = deepbit_block_distribution.resample('ME').size()\n",
    "\n",
    "# Visualizzazione\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(18, 12), sharex=False)\n",
    "fig.suptitle('Distribuzione dei blocchi minati da Deepbit.net', fontsize=16)\n",
    "\n",
    "# Line plots (sinistra)\n",
    "axs[0, 0].plot(daily.index, daily.values, label='Giornaliero', color='blue')\n",
    "axs[0, 0].set_title('Blocchi minati - Giornaliero')\n",
    "axs[0, 0].set_ylabel('Blocchi')\n",
    "axs[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axs[1, 0].plot(weekly.index, weekly.values, label='Settimanale', color='green')\n",
    "axs[1, 0].set_title('Blocchi minati - Settimanale')\n",
    "axs[1, 0].set_ylabel('Blocchi')\n",
    "axs[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axs[2, 0].plot(monthly.index, monthly.values, label='Mensile', color='orange')\n",
    "axs[2, 0].set_title('Blocchi minati - Mensile')\n",
    "axs[2, 0].set_ylabel('Blocchi')\n",
    "axs[2, 0].set_xlabel('Data')\n",
    "axs[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plots (destra)\n",
    "axs[0, 1].bar(daily.index, daily.values, color='blue')\n",
    "axs[0, 1].set_title('Bar plot - Giornaliero')\n",
    "axs[0, 1].set_ylabel('Blocchi')\n",
    "axs[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axs[1, 1].bar(weekly.index, weekly.values, color='green', width=5)\n",
    "axs[1, 1].set_title('Bar plot - Settimanale')\n",
    "axs[1, 1].set_ylabel('Blocchi')\n",
    "axs[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axs[2, 1].bar(monthly.index, monthly.values, color='orange' , width=20)\n",
    "axs[2, 1].set_title('Bar plot - Mensile')\n",
    "axs[2, 1].set_ylabel('Blocchi')\n",
    "axs[2, 1].set_xlabel('Data')\n",
    "axs[2, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f9aeb",
   "metadata": {},
   "source": [
    "### 2) DeepBit.net's fee distribution\n",
    "\n",
    "Find how fee transactions are distributed to the DeepBit.net's mining pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify ouputs amounts for the first transaction\n",
    "renamed_outputs = outputs.copy()\n",
    "renamed_outputs.rename(columns={'txId': 'prevTxId', 'position': 'prevTxpos'}, inplace=True)\n",
    "fee_info= renamed_outputs.merge(deepbit_mined_block_transact, on=['prevTxId','prevTxpos']).merge(transactions[['txId', 'blockId', 'fee']], on='txId')\n",
    "fee_info['timestamp'] = pd.to_datetime(fee_info['timestamp'], unit='s')\n",
    "fee_info.set_index('timestamp', inplace=True)\n",
    "\n",
    "\n",
    "first_btc_halving_blockId = 210000\n",
    "fee_info['amount'] = fee_info['amount'] / 1e8  # Convert from satoshis to BTC\n",
    "\n",
    "fee_subtract = (fee_info['blockId'] < first_btc_halving_blockId).map({True: 50, False: 25})\n",
    "fee_info['fee_btc'] = (fee_info['amount']+fee_info['fee'] - fee_subtract).round(8)\n",
    "\n",
    "\n",
    "\n",
    "# 1) Aggregazioni\n",
    "daily_fee   = fee_info['fee_btc'].resample('D').sum()\n",
    "weekly_fee  = fee_info['fee_btc'].resample('W').sum()\n",
    "monthly_fee = fee_info['fee_btc'].resample('ME').sum()\n",
    "# Usa un unico subplot per mostrare le tre aggregazioni fee (giornaliera, settimanale, mensile) con scala log\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(18, 12), sharex=False)\n",
    "fig.suptitle('Distribuzione delle fee da Deepbit.net', fontsize=16)\n",
    "\n",
    "\n",
    "axs[0,0].bar(daily_fee.index, daily_fee.values)\n",
    "axs[0,0].set_title('Fee BTC giornaliere')\n",
    "axs[0,0].set_xlabel('Data')\n",
    "axs[0,0].set_ylabel('Totale fee (BTC)')\n",
    "axs[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar-plot settimanale\n",
    "axs[1,0].bar(weekly_fee.index, weekly_fee.values, color='green',width= 5)\n",
    "axs[1,0].set_title('Fee BTC settimanali ')\n",
    "axs[1,0].set_xlabel('Settimana (fine settimana)')\n",
    "axs[1,0].set_ylabel('Totale fee (BTC)')\n",
    "axs[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar-plot mensile\n",
    "axs[2,0].bar(monthly_fee.index, monthly_fee.values, color='orange', width= 20)\n",
    "axs[2,0].set_title('Fee BTC mensili')\n",
    "axs[2,0].set_xlabel('Mese')\n",
    "axs[2,0].set_ylabel('Totale fee (BTC)')\n",
    "axs[2,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar-plot giornaliero\n",
    "axs[0,1].bar(daily_fee.index, daily_fee.values)\n",
    "axs[0,1].set_yscale('log')\n",
    "axs[0,1].set_title('Fee BTC giornaliere (scala log)')\n",
    "axs[0,1].set_xlabel('Data')\n",
    "axs[0,1].set_ylabel('Totale fee (BTC)')\n",
    "axs[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar-plot settimanale\n",
    "axs[1,1].bar(weekly_fee.index, weekly_fee.values, color='green',width= 5)\n",
    "axs[1,1].set_yscale('log')\n",
    "axs[1,1].set_title('Fee BTC settimanali (scala log)')\n",
    "axs[1,1].set_xlabel('Settimana (fine settimana)')\n",
    "axs[1,1].set_ylabel('Totale fee (BTC)')\n",
    "axs[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar-plot mensile\n",
    "axs[2,1].bar(monthly_fee.index, monthly_fee.values, color='orange', width= 20)\n",
    "axs[2,1].set_yscale('log')\n",
    "axs[2,1].set_title('Fee BTC mensili (scala log)')\n",
    "axs[2,1].set_xlabel('Mese')\n",
    "axs[2,1].set_ylabel('Totale fee (BTC)')\n",
    "axs[2,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75a5b1",
   "metadata": {},
   "source": [
    "### 3) DeepBit.net's UTXO distribution\n",
    "\n",
    "Compute the UTXO (Unspent Transaction Output) distribution of the DeepBit.net for each month in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ce2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTXO are related to the unspent outputs of a transaction. Thus let's look for the outputs that \n",
    "utxo_transactions = outputs.copy().merge(deepbit_transactions[['txId', 'timestamp']], on='txId')\n",
    "utxo_transactions.rename(columns={'txId': 'prevTxId', 'position': 'prevTxpos'}, inplace=True)\n",
    "\n",
    "spent_utxo = utxo_transactions.merge(inputs[['prevTxId', 'prevTxpos']],on=['prevTxId', 'prevTxpos'], how='left', indicator='is_spent')\n",
    "\n",
    "# Identify unspent UTXO\n",
    "unspent_utxo = spent_utxo[spent_utxo['is_spent'] == 'left_only'].drop(columns=['is_spent'])\n",
    "\n",
    "unspent_utxo['amount'] = unspent_utxo['amount'] / 1e8  # Convert from satoshis to BTC\n",
    "unspent_utxo['timestamp'] = pd.to_datetime(unspent_utxo['timestamp'], unit='s')\n",
    "\n",
    "# unspent_utxo['month_end'] = unspent_utxo['timestamp'].to\n",
    "\n",
    "\n",
    "all_dates = pd.date_range(\n",
    "    start=unspent_utxo['timestamp'].min().to_period('M').to_timestamp(),\n",
    "    end=unspent_utxo['timestamp'].max(),\n",
    "    freq='ME'\n",
    ")\n",
    "\n",
    "all_dates = all_dates.floor('D') + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)\n",
    "\n",
    "# Calculate monthly UTXO\n",
    "monthly_utxo =[]\n",
    "\n",
    "\n",
    "for month_end in all_dates:\n",
    "    before_month_end_utxo = unspent_utxo[unspent_utxo['timestamp'] < month_end]\n",
    "    sum_utxo_btc = before_month_end_utxo['amount'].sum()\n",
    "    utxo_count = before_month_end_utxo['amount'].count()\n",
    "    monthly_utxo.append([month_end, sum_utxo_btc, utxo_count])\n",
    "\n",
    "monthly_utxo_df = pd.DataFrame(monthly_utxo, columns=['month', 'utxo_btc', 'utxo_count'])\n",
    "print(monthly_utxo_df.head(5))\n",
    "print(f\"Number of monthly UTXO: {len(monthly_utxo_df)}\")\n",
    "\n",
    "\n",
    "# Visualize the monthly UTXO using bar plots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "fig.suptitle('Distribuzione mensile degli UTXO di DeepBit.net', fontsize=16)\n",
    "\n",
    "# Bar plot UTXO BTC\n",
    "axs[0].bar(monthly_utxo_df['month'], monthly_utxo_df['utxo_btc'], color='tab:blue', width=20, align='center')\n",
    "axs[0].set_ylabel('UTXO (BTC)')\n",
    "axs[0].set_title('Somma UTXO mensili (BTC)')\n",
    "axs[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plot UTXO Count\n",
    "axs[1].bar(monthly_utxo_df['month'], monthly_utxo_df['utxo_count'], color='tab:orange', width=20, align='center')\n",
    "axs[1].set_ylabel('Numero UTXO')\n",
    "axs[1].set_title('Numero UTXO mensili')\n",
    "axs[1].set_xlabel('Mese')\n",
    "axs[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33dfd2",
   "metadata": {},
   "source": [
    "## Deepbit.net graphs parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde3f8c",
   "metadata": {},
   "source": [
    "Preparing the data for the graphs of DeepBit.net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Find the transaction with txId 1883820\n",
    "transaction = transactions[transactions['txId'] == 1883820].merge(outputs, on='txId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0a27a",
   "metadata": {},
   "source": [
    "### 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadbadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepbit_graph = nx.MultiDiGraph()\n",
    "\n",
    "# Initially add the unique output addresses to the graph\n",
    "\n",
    "# Aggiungi nodo con tutti gli attributi della riga\n",
    "deepbit_graph.add_node(transaction.iloc[0]['txId'])\n",
    "\n",
    "\n",
    "output_info = outputs.copy()\n",
    "\n",
    "current_transaction = transaction\n",
    "\n",
    "OthersDeepbit =set() # outputs not belonging to Deepbit.net\n",
    "\n",
    "while True:\n",
    "    # Find the inputs for the current transaction\n",
    "    print(f\"Processing transaction {current_transaction.iloc[0]['txId']}...\")\n",
    "    outs = output_info.merge(current_transaction['txId'], on='txId')\n",
    "    \n",
    "    # check if there is a Deepbit.net address\n",
    "    check_deepbit_addr= outs.merge(deepbit_mapped_addresses, on='addressId', how='left', indicator='is_deepbit').rename(columns={'txId': 'prevTxId', 'position': 'prevTxpos'})\n",
    "    deepbit_addrs = check_deepbit_addr[check_deepbit_addr['is_deepbit'] == 'both']\n",
    "    other_addrs = check_deepbit_addr[check_deepbit_addr['is_deepbit'] == 'left_only']\n",
    "\n",
    "    if len(deepbit_addrs) !=1 :\n",
    "        print(f\"Stop: trovati {len(check_deepbit_addr)} change-outputs in tx {current_transaction.iloc[0]['txId']}\")\n",
    "        break\n",
    "    if not other_addrs.empty:\n",
    "        # Add the outputs that do not belong to Deepbit.net to the set\n",
    "        OthersDeepbit.update(other_addrs['addressId'].unique())\n",
    "        print(f\"Found {len(OthersDeepbit)} outputs that do not belong to Deepbit.net in tx {current_transaction.iloc[0]['txId']}\")\n",
    "\n",
    "    \n",
    "    # Find the next transaction\n",
    "    next_transactions = inputs.merge(deepbit_addrs, on=['prevTxId', 'prevTxpos'])#.rename(columns={'prevTxId':'txId', 'prevTxpos':'position' })\n",
    "    if next_transactions.empty:\n",
    "        print(f\"Stop: la catena della transazione {current_transaction['txId']} si ferma qui.\")\n",
    "        break\n",
    "    # Add the next transaction to the graph\n",
    "\n",
    "    next_tx_id = next_transactions.iloc[0]['txId']\n",
    "\n",
    "    print(f\"Adding transaction {next_tx_id} to the graph\")\n",
    "    deepbit_graph.add_node(next_tx_id)\n",
    "    # Add an edge from the current transaction to the next transaction\n",
    "    \n",
    "    current_tx_id = current_transaction.iloc[0]['txId']\n",
    "    change_address = deepbit_addrs.iloc[0]['addressId']  # Indirizzo di change\n",
    "    \n",
    "    deepbit_graph.add_edge(current_tx_id,next_tx_id, change_address=change_address)\n",
    "    print(f\"Added edge from {current_tx_id} to {next_tx_id} with change address {change_address}\")\n",
    "    # Update the current transaction to the next one\n",
    "    current_transaction = next_transactions\n",
    "\n",
    "print(f\"Total number of transactions in the graph: {deepbit_graph.number_of_nodes()}\")\n",
    "print(f\"Number of OthersDeepbit addresses: {len(OthersDeepbit)}\")\n",
    "\n",
    "# Plot the graph \n",
    "posizione_circular = nx.random_layout(deepbit_graph)\n",
    "nx.draw_networkx(deepbit_graph, pos= posizione_circular, node_color='lightblue', font_size=7, font_color='black', arrows=True, node_size=100)\n",
    "# Highlight the start node in red\n",
    "nx.draw_networkx_nodes(deepbit_graph, nodelist=[list(deepbit_graph.nodes())[0]], node_color='red', node_size=200, label='Start Node', pos=posizione_circular)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621c7f7",
   "metadata": {},
   "source": [
    "# 2)\n",
    "\n",
    "per ogni coppia di transazioni ti, ti+1 della catena calcolare rispettivamente, la differenza tra i timestamp delle due transazioni e tra i valori inviati sui change address e visualizzare le differenze ottenute su un grafico;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24b603",
   "metadata": {},
   "source": [
    "## DiceOnCrack.com gambling service analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if diceoncrack_wallet_addresses is None:\n",
    "    #in case of error in the scraping process, we can use a predefined list of wallet addresses\n",
    "diceoncrack_wallet_addresses = pd.Series([\n",
    "    \"12TaAbLWBNKB1NLYH92CPnC1DizQoNK6FN\",\n",
    "    \"1CRACkbiJSxfDaLNEoaNsHjNtU4KttwHyo\",\n",
    "    \"1CRACKafkXsQzUYmu2fUM3j9c2y4yDhvfh\",\n",
    "    \"1CRACKLiwFrZbAQz1yb9w22onHCMLbiMTY\",\n",
    "    \"12tAabLFLxvUzC5KuX7VKMM8bYRncbQ84E\",\n",
    "    \"1CrAcKt3HE8LNsx4KKDvjqLvcr373wg5ke\",\n",
    "    \"1AVFypuG2jUrYzjZa69C7hK59XkWUwvK1m\",\n",
    "    \"1CRACK25QvpVdcEmPZVD5ixtf99cMF9stg\",\n",
    "    \"1CracksLRtQMcTF4HXNrvPzRgvz7Qr6wNd\",\n",
    "    \"13TAabLHjNzwg8Mj7XYn76FuVAqj32s8EM\",\n",
    "    \"1CrAckQppdcfiiw4XzpsKrZrf9eDvUok9C\",\n",
    "    \"19TAABLQTLxgWHTdm7yNJNstgeQFgxTP4f\",\n",
    "    \"14TAAbLiw2QLuRJCGQ3iETYg3vcpweZkTE\",\n",
    "    \"15TaABLmhxiRQ9DTX6ZcZ9S9RknVZmP5jX\",\n",
    "    \"1tAabLBcZLVL7md9nAnvGMCYdbvq4UVZV\",\n",
    "    \"1PipEaL8yRS8n93mUS16wT5SNDiMrMutv5\",\n",
    "    \"1PipemCUjxq9LKww7CaLWUMeGVZL3bD3VM\",\n",
    "    \"1LQXotaEjfmerkwrGB3dHnheujo7sng6vA\",\n",
    "    \"1PipeBMryPGnN3Ms3HfnNjetCS4THmkpkS\",\n",
    "    \"1PipeZHgQXcjAYsUQ4WRXyKZn1X3sJNrpk\",\n",
    "    \"1PipePezjvE7vBukPyDUkhHEF54qK1nkeu\",\n",
    "    \"1Q44t4knYY3PsQZUFAejhd7Wot79ecHe8e\",\n",
    "    \"1F4VXTQRzVQfLaGEWcf697xj1g2cKqPire\",\n",
    "    \"1Pipeb5iNYmURifrxPZfvwHsTiw9rEb2iu\",\n",
    "    \"1PipeZofhJv1hxsxCadEeG1vHAK87f23LE\",\n",
    "    \"17ZmFwCULT44K25kWDeYbHiGaJCrWtytjx\",\n",
    "    \"13encD1Yagh8M6a9Wgb3YJxKHrHqXnYi8y\",\n",
    "    \"1GD2EiVa1rbbXcmFceyM47YN16fzVwn9j\"\n",
    "],name='hash')\n",
    "\n",
    "\n",
    "diceoncrack_mapped_addresses = map_wallet_addresses(diceoncrack_wallet_addresses, mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2a53a",
   "metadata": {},
   "source": [
    "### 1) Find the transaction of DiceOnCrack.com which are the transactions that have at least one input or output address of DiceOnCrack.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the transactions related to DiceOnCrack.com\n",
    "diceoncrack_transactions = find_wallet_transactions(diceoncrack_mapped_addresses, transactions, inputs, outputs)\n",
    "# Order by blockId in ascending order\n",
    "diceoncrack_transactions = diceoncrack_transactions.sort_values(by='blockId', ascending=True)\n",
    "print(f\"Number of transactions related to DiceOnCrack.com: {len(diceoncrack_transactions)}\")\n",
    "# DEBUG\n",
    "# print(diceoncrack_transactions.head(20))\n",
    "# print(diceoncrack_transactions.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47b271",
   "metadata": {},
   "source": [
    "### 2) Group transactions by block height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_diceoncrack_transactions_by_block(diceoncrack_transactions):\n",
    "    \"\"\"Groups DiceOnCrack.com transactions by blockId.\"\"\"\n",
    "    \n",
    "    #find the group of transactions that have the same blockId\n",
    "    grouped_transactions = diceoncrack_transactions.groupby('blockId')\n",
    "    return grouped_transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5083dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "REQUEST_INTERVAL = 10  # secondi tra le richieste\n",
    "\n",
    "def get_wallet_hash(address):\n",
    "    \"\"\"Effettua scraping su Wallet Explorer per ottenere l'hash del wallet dato un address\"\"\"\n",
    "\n",
    "    \n",
    "    url = f\"https://www.walletexplorer.com/?q={address}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "    \n",
    "    try:\n",
    "        time.sleep(REQUEST_INTERVAL)  # Attendi tra le richieste per evitare blocchi\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=50)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Tentativo 1: Cerca nel div header\n",
    "        main_div = soup.find('div',id='main')\n",
    "        h2_tag = main_div.find('h2') if main_div else None\n",
    "        \n",
    "        if h2_tag:\n",
    "            # Prendi il testo completo\n",
    "            full = h2_tag.get_text(separator=' ').strip()\n",
    "            # Estrai tutte le sottostringhe fra virgolette doppie\n",
    "            quoted = full.split(' ')\n",
    "            # Pulisci gli elementi e verifica che ci sia almeno un secondo elemento\n",
    "            cleaned = [s.strip() for s in quoted]\n",
    "            if len(cleaned) >= 2:\n",
    "                wallet_hash = cleaned[2]\n",
    "                if wallet_hash[0] == '[' and wallet_hash[-1] == ']':\n",
    "                    # Rimuovi le parentesi quadre\n",
    "                    wallet_hash = wallet_hash[1:-1]\n",
    "                # cache e rate‑limit\n",
    "                # print(f\"Wallet hash trovato per {address}: {wallet_hash}\")\n",
    "                # get_wallet_hash.last_request_time = current_time\n",
    "                return wallet_hash\n",
    "        \n",
    "        # Se non trovato\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante lo scraping per {address}: {str(e)}\")\n",
    "        return None\n",
    "    # finally:\n",
    "        # get_wallet_hash.last_request_time = time.time()\n",
    "\n",
    "def cluster_by_wallet(group_info, diceoncrack_wallet_ids):\n",
    "\n",
    "    grouped_infor_by_txid = group_info.groupby('txId')\n",
    "\n",
    "    cluster_info =[]\n",
    "\n",
    "    inputs_current_transactions= inputs.merge(group_info,on ='txId')\n",
    "    renamed_outputs = outputs.rename(columns={'txId': 'prevTxId', 'position': 'prevTxpos'})\n",
    "    tmp = inputs_current_transactions.merge(renamed_outputs, on=['prevTxId', 'prevTxpos'])\n",
    "    \n",
    "\n",
    "    for tx_id, group in grouped_infor_by_txid:\n",
    "\n",
    "        inputs_mapped_address= tmp[tmp['txId'] == tx_id]['addressId']\n",
    "        if inputs_mapped_address.empty:\n",
    "            print(f\"No inputs found for txId {tx_id}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing txId {tx_id} with {len(inputs_mapped_address)} input addresses.\")\n",
    "\n",
    "        # Exclude the cluster if any address belongs to DiceOnCrack\n",
    "        # a =inputs_mapped_address # DEBUG\n",
    "        inputs_mapped_address = inputs_mapped_address[inputs_mapped_address.isin(diceoncrack_wallet_ids) == False]\n",
    "        if inputs_mapped_address.empty:\n",
    "            print(f\"Skipping txId {tx_id} due to no valid addresses.\")\n",
    "            continue\n",
    "\n",
    "        input_address = mapping.merge(inputs_mapped_address, on='addressId')['hash']\n",
    "\n",
    "        print(\"\\nIndirizzi da controllare:\", input_address.tolist(),\"\\n\")\n",
    "        cluster_wallet = get_wallet_hash(input_address.iloc[0])  # Prendi il wallet hash del primo address\n",
    "        if len(input_address) > 1:\n",
    "            for addr in input_address:\n",
    "                try:\n",
    "                    wallet_hash = get_wallet_hash(addr)\n",
    "                    if wallet_hash != cluster_wallet:\n",
    "                        print(f\"Cluster skipped for txId {tx_id} due to different wallet hashes.\")\n",
    "                        cluster_wallet = None\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error while getting wallet hash for address {addr}: {e}\")\n",
    "                    break\n",
    "        \n",
    "        if cluster_wallet is None:\n",
    "            # print(f\"Skipping cluster for txId {tx_id} due to inconsistent wallet hashes.\")\n",
    "            continue\n",
    "        else:\n",
    "            # print(f\"Cluster for txId {tx_id} belongs to wallet: {cluster_wallet}\")\n",
    "            # save the cluster information\n",
    "            cluster_info.append({\n",
    "                'txId': tx_id,\n",
    "                'wallet': cluster_wallet,\n",
    "                'num_addresses': len(input_address)})\n",
    "\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    cluster_wallets = pd.DataFrame(cluster_info, columns=['txId', 'wallet','num_addresses']) if len(cluster_info) > 0 else pd.DataFrame()\n",
    "    # print(cluster_wallets.info())\n",
    "    # print(cluster_wallets.head(5))\n",
    "    # print(\"------------------------------------\\n\")\n",
    "    # print(f\"Number of clusters found: {len(cluster_wallets)}\")\n",
    "    # print(cluster_wallets.head(20))\n",
    "    return cluster_wallets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the period : example starting from 26/12/2012\n",
    "\n",
    "diceoncrack_transactions['timestamp'] = pd.to_datetime(diceoncrack_transactions['timestamp'], unit='s')\n",
    "\n",
    "starting_period = pd.to_datetime('2012-12-26')\n",
    "\n",
    "diceoncrack_transactions = diceoncrack_transactions[diceoncrack_transactions['timestamp'] >= starting_period]\n",
    "\n",
    "print(f\"Number of transactions after filtering by date: {len(diceoncrack_transactions)}\")\n",
    "# print(diceoncrack_transactions.head(5))\n",
    "\n",
    "groups = group_diceoncrack_transactions_by_block(diceoncrack_transactions)\n",
    "print(f\"Number of blocks with DiceOnCrack.com transactions: {len(groups)}\")\n",
    "# # DEBUG\n",
    "# print(groups.head(20))\n",
    "# print(groups.head(5))\n",
    "\n",
    "# Esempio di utilizzo\n",
    "frames = []\n",
    "\n",
    "for block_id, group in groups:\n",
    "    tx_ids = group['txId']\n",
    "    \n",
    "    # Ottimizzazione: calcola tutto in vettori\n",
    "    clusters = cluster_by_wallet(\n",
    "        group_info=group,\n",
    "        diceoncrack_wallet_ids=diceoncrack_mapped_addresses\n",
    "    )\n",
    "    print(\"Clusters\\n\", clusters.head(15)) #DEBUG\n",
    "\n",
    "    if len(clusters) > 0:\n",
    "        clusters['blockId'] = block_id\n",
    "        frames.append(clusters)\n",
    "\n",
    "# all_clusters['blockId'] = groups['blockId']\n",
    "\n",
    "all_clusters = pd.concat(frames, ignore_index=True, axis=0) if frames else pd.DataFrame()\n",
    "\n",
    "print(all_clusters.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For DEBUG purposes\n",
    "## Create a cache for the cluster wallets research\n",
    "# In this case the file save the research of the clusters wallets starting from 27/12/2012\n",
    "try:\n",
    "    all_clusters.to_csv('cluster_results_26_12_2012.csv', \n",
    "                       index=False, \n",
    "                       encoding='utf-8')  # -sig per compatibilità Excel\n",
    "    print(\"File salvato correttamente\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore nel salvataggio: {e}\")\n",
    "\n",
    "#Load the clusters from the file if it exists\n",
    "if all_clusters.empty or all_clusters is None:\n",
    "    all_clusters = pd.read_csv('cluster_results_27_12_2012.csv', \n",
    "                               encoding='utf-8')  # -sig per compatibilità Excel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6252705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Calcola la dimensione media dei cluster per ogni blocco, considerando solo cluster con almeno 2 indirizzi\n",
    "if not all_clusters.empty:\n",
    "    # Filtra prima i cluster con almeno 2 indirizzi\n",
    "    filtered = all_clusters[all_clusters['num_addresses'] >= 2]\n",
    "    \n",
    "    # Calcola la media per blocco\n",
    "    avg_cluster_size_per_block = filtered.groupby('blockId')['num_addresses'].mean().reset_index()\n",
    "\n",
    "    if not avg_cluster_size_per_block.empty:\n",
    "        print(\"Dimensione media dei cluster (>=2) per blocco:\")\n",
    "        # print(avg_cluster_size_per_block)\n",
    "        \n",
    "        # Grafico\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        avg_cluster_size_per_block.plot(kind='bar', x='blockId', y='num_addresses', legend=False)\n",
    "        plt.title('Dimensione media dei cluster (>=2) per blocco')\n",
    "        plt.xlabel('blockId')\n",
    "        plt.ylabel('Dimensione media cluster')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Nessun cluster con almeno 2 indirizzi trovato.\")\n",
    "else:\n",
    "    print(\"Nessun cluster disponibile per il calcolo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed96c54",
   "metadata": {},
   "source": [
    "#### 4) Discussion about\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
